# ============================================
# 芯片失效分析AI Agent系统 - Docker环境变量配置
# ============================================
# 复制此文件为 .env 并修改相应的值

# ============================================
# LLM API配置 (必需)
# ============================================

# 选项 1: Anthropic Claude (默认)
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_MODEL=claude-3-opus-20240229

# 选项 2: OpenAI
# OPENAI_API_KEY=your_openai_key_here
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4-turbo

# 选项 3: 本地 Qwen3 (vLLM/Ollama/Xinference)
# OPENAI_API_KEY=your_api_key_here
# OPENAI_API_BASE=http://localhost:8000/v1
# OPENAI_MODEL=Qwen/Qwen2-7B-Instruct
#
# 说明:
#   vLLM 启动: vllm serve Qwen/Qwen2-7B-Instruct --host 0.0.0.0 --port 8000
#   Ollama 启动: ollama run qwen:7b (默认端口 11434)
#   Xinference: xinference-local --port 9997

# ============================================
# 应用配置
# ============================================
APP_ENV=production
APP_DEBUG=false
LOG_LEVEL=INFO

# ============================================
# 数据库密码配置
# ============================================
POSTGRES_PASSWORD=postgres
NEO4J_PASSWORD=neo4j-secret-password
REDIS_PASSWORD=redis_password

# ============================================
# Embedding配置
# ============================================
EMBEDDING_BACKEND=bge
EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
EMBEDDING_DEVICE=cpu
EMBEDDING_DIMENSIONS=1024

# ============================================
# 前端API地址
# ============================================
VITE_API_BASE_URL=http://localhost:8889

# ============================================
# 上下文管理配置（适配 64KB 限制的 LLM）
# ============================================
CONTEXT_LIMIT_KB=64
CONTEXT_LOG_TARGET_KB=35
CONTEXT_CONVERSATION_MAX_KB=10
CONTEXT_MAX_RECENT_MESSAGES=3
CONTEXT_AUTO_COMPRESS=true
CONTEXT_USE_SEMANTIC=true
CONTEXT_SIMILARITY_THRESHOLD=0.3
CONTEXT_MIN_PRESERVE_LINES=50
CONTEXT_PRESERVE_RATIO=0.5
CONTEXT_USE_CLAUDE_STYLE=true
CONTEXT_TARGET_TOKENS=18000
LLM_MAX_OUTPUT_TOKENS=2000
